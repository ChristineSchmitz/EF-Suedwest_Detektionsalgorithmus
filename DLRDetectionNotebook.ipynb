{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "Please set the necessary variables in the cell below\n",
    "\n",
    "Please read the settings description below\n",
    "\n",
    "After setting everything just run the notebook or the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dumsv\\anaconda3\\envs\\DLR-Detection\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-6-23 Python-3.8.15 torch-1.12.1 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 1764577 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "Starting general Detection\n",
      "Saving results\n",
      "Done!\n",
      "\n",
      "Total amount of apples detected: 86.2\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "\n",
    "from DLRDetectionUtils import DLRNotebook\n",
    "\n",
    "# Required settings\n",
    "# Please adjust them according to your use case\n",
    "# Please see the GitHub page for a list of use cases and the parameter description below for further information\n",
    "imgpath = [\"./test/*.jpeg\"] \n",
    "          # Path to the folder were images are in\n",
    "          # Can contain multiple paths\n",
    "general = True\n",
    "crop = False\n",
    "splitcameras = False \n",
    "combine = False \n",
    "multirowaverage = False\n",
    "\n",
    "# Additional settings\n",
    "# These depend on the use case\n",
    "# Please see the parameter description below for further information\n",
    "trees = 0 # Number of trees\n",
    "reference = [0, 0, 0, 0] # Reference coordinates of the first an last tree in the row\n",
    "\n",
    "# Optional settings\n",
    "conf_thresh = 0.3 \n",
    "version = 3 \n",
    "weights = './model/DLR-Detection-v3.pt' \n",
    "live = False \n",
    "wmean = False\n",
    "show_label = False \n",
    "\n",
    "# Running detection\n",
    "DLRNotebook(general=general,\n",
    "            combine=combine,\n",
    "            splitcameras=splitcameras,\n",
    "            multirowaverage=multirowaverage,\n",
    "            trees=trees,\n",
    "            references=reference,\n",
    "            imgpaths=imgpath,\n",
    "            conf_thresh=conf_thresh,\n",
    "            version=version,\n",
    "            weights=weights,\n",
    "            live=live,\n",
    "            wmean=wmean,\n",
    "            crop=crop,\n",
    "            show_label=show_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings explanation\n",
    "\n",
    "#### ***imgpath***\n",
    "**Options**: text string\n",
    "\n",
    "Full path to the folder where the images are located. \n",
    "\n",
    "Please add the file extension of the images at the end of the path.\n",
    "\n",
    "Can contain multiple paths in a list. If multiple path are given, they will be processed in sequence.\n",
    "\n",
    "Example path:\n",
    "<br>\n",
    "\"C:/Users/dumsv/Uni/YOLOv5/Ernte2022/Test/_images/*.jpeg\"\n",
    "\n",
    "Example for multiple paths:\n",
    "<br>\n",
    "[\"C:/Users/dumsv/Uni/YOLOv5/Ernte2022/Test/_images/*.jpeg\",\"C:/Users/dumsv/Uni/YOLOv5/Ernte2022/Test2/_images/*.jpeg\"]\n",
    "\n",
    "#### ***general***\n",
    "**Options**: True or False, **default**: False\n",
    "\n",
    "If set to True, all images in the designated folder will be fed to the model. The images will not be automatically filtered.\n",
    "\n",
    "Use this option if your images are already filtered, so you have one tree per image. If you have images from three cameras, please make sure they are in subfolders inside the folder called \"camera1\", \"camera2\" and \"camera3\". These subfolders should be inside the folder set by ***imgpath***.\n",
    "\n",
    "#### ***crop***\n",
    "**Options**: True or False, **default**: False\n",
    "\n",
    "Only works when using three cameras. This will crop the top and bottom images to reduce overlap. From the top image, the bottom quarter of the image will be cut. Form the bottom image, the top quarter of the image will be cut. The original images will be deleted so please make backups. This also assumes that camera03 is the top camera and camera01 is the bottom camera.\n",
    "\n",
    "This also only works with **splitcameras** set to True. After using this option please set **splitcameras** and **crop** to False.\n",
    "\n",
    "#### ***splitcameras***\n",
    "Options: True or False, **default**: False\n",
    "\n",
    "If set to True, the images in the designated folder will be split into three subfolders called \"camera1\", \"camera2\" and \"camera3\". For this the designated folder must contain all images from the three cameras and the file names must contain \"camera0X\", with X being the number of the camera.\n",
    "\n",
    "Use this option if you have images from three cameras but they are not yet split into three subfolders. Set to False after images are split.\n",
    "\n",
    "After the split, the folders will be automatically equalized. See **EqualizeFolders** in **DLRDetectionUtils.py** for further information.\n",
    "\n",
    "This will always split into three cameras. Two cameras or more than three cameras are not supported.\n",
    "\n",
    "#### ***combine***\n",
    "**Options**: True or False, **default**: False\n",
    "\n",
    "If set to True, matching images from different cameras will be combined. As a result we have a single sequence of combined images instead of one sequence for each camera. For this the folder can contain either the three different subfolders or all images.\n",
    "\n",
    "Will only be used if ***splitcameras*** is also set to True.\n",
    "\n",
    "Can be useful for manual filtering, so you dont have to filter three different sequences.\n",
    "\n",
    "The program will exit after finishing combining the images. Please set ***splitcameras*** and ***combine*** to False after using this option.\n",
    "\n",
    "#### ***multirowaverage***\n",
    "**Options**: True or False, **default**: False\n",
    "\n",
    "Flag if the given rows will be averaged. This is meant for averaging the same row captured from two different sides. Assumes that the capture direction of the rows are opposite and will flip the order of the second row in order to match it to the first row.\n",
    "\n",
    "#### ***trees***\n",
    "**Options**: integer, **default**: 0\n",
    "\n",
    "This setting is required if ***general*** is set to False. \n",
    "\n",
    "Sets the number of trees in a row.\n",
    "\n",
    "#### ***reference***\n",
    "**Options**: ellipsoidal or cartesian coordinates\n",
    "\n",
    "This setting is required if ***general*** is set to False.\n",
    "Sets the coordinates of the first and last tree. These are used for the automatic filter. \n",
    "\n",
    "Coordinates can either be in ellipsoidal Lattitude and Longitude or cartesian X and Y coordinates.\n",
    "\n",
    "Please set the coordinates in the following format:\n",
    "<br>\n",
    "[X_Coordinate first tree, Y_Coordinate first tree, X_coordinate last tree, Y_coordinate last tree]\n",
    "<br>\n",
    "or\n",
    "<br>\n",
    "[Lattitude first tree, Longitude first tree, Lattitude last tree, Longitude last tree]\n",
    "\n",
    "#### ***conf_thresh***\n",
    "**Options**: float between 0 and 1, **default**: 0.3\n",
    "\n",
    "This sets the confidence threshold for the model. Every detection with a confidence below the threshold will be disregarded.\n",
    "\n",
    "#### ***version***\n",
    "**Options**: 1,2 or 3, **default**: 3\n",
    "\n",
    "Deprecated option, should not be changed.\n",
    "\n",
    "#### ***weights***\n",
    "**Options**: text string, **default**: './model/DLR-Detection-v3.pt'\n",
    "\n",
    "Path to the weights used for the model. The default weights are tuned for Apple, bud, flower, and tree detection. \n",
    "\n",
    "#### ***live***\n",
    "**Options**: True or False, **default**: False\n",
    "\n",
    "If set to true, all images in the designated folder will be fed to the model. The folder will be continuously scanned for new images. The program will exit after a set amount of time if no images are added to the folder\n",
    "\n",
    "#### ***wmean***\n",
    "**Options**: True or False, **default**: False\n",
    "\n",
    "If the to true, enables weighted average of neighboring images. The number of detections on a single tree will be averaged over multiple images. The images are weighted based on their distance to the center tree. This distance is based on the GPS postition embeded in the images. Takes longer to process"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLR-Detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
